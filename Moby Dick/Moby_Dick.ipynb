{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#####**UNIVERSIDAD AUTONOMA DE CHIHUAHUA**\n",
        "#####**FACULTAD DE INGENIERIA**\n",
        "#####**MOBY DICK**\n",
        "#####**NOMBRE:** JOHANN LOZANO ENRIQUEZ\n",
        "#####**GRUPO:** 8CC2\n",
        "#####**MATRICULA:** 338834\n",
        "#####**DOCENTE:** JESUS ROBERTO LOPEZ SANTILLAN\n",
        "#####**MATERIA:** DATA SCIENCE\n",
        "#####***Chihuahua, Chih. 28 de Noviembre del 2023***"
      ],
      "metadata": {
        "id": "aZL0t6FmOFJP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQR4qbUdNEJK",
        "outputId": "8e9dcc6b-2cb2-4e4e-e5c1-41758a57ebeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/cache/epub/2701/pg2701.txt\n",
            "1276266/1276266 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "moby_url = \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\" # shortcut URL\n",
        "filepath = keras.utils.get_file(\"moby.txt\", moby_url)\n",
        "with open(filepath) as f:\n",
        "  moby_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts([moby_text])"
      ],
      "metadata": {
        "id": "j3J4NWUZNqQY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([\"First\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8CSlwAlNqvq",
        "outputId": "5a7aab57-7dd4-447f-f208-70c34f8eb517"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 7, 10, 8, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts([[19, 7, 10, 8, 3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puz7bb7ZNsc5",
        "outputId": "311a34d1-823c-4233-950d-678e9ead8e83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_id = len(tokenizer.word_index) # number of distinct characters\n",
        "#dataset_size = tokenizer.document_count # total number of character\n",
        "dataset_size = sum([x for _,x in tokenizer.word_counts.items()])\n",
        "print(max_id)\n",
        "print(dataset_size)\n",
        "print(type(dataset_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-u9wSgkNucy",
        "outputId": "ef1679da-ad94-4d48-d655-5414b09ee1a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77\n",
            "1238203\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "[encoded] = np.array(tokenizer.texts_to_sequences([moby_text])) - 1"
      ],
      "metadata": {
        "id": "sX1Mya77NvnR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_size = dataset_size * 90 // 100\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "metadata": {
        "id": "U1Cd8CzgNxsj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 100\n",
        "window_length = n_steps + 1\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "3dwojCaANzBe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "metadata": {
        "id": "DwNqEdeoN1Pk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "metadata": {
        "id": "1_KKlMRUN28T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")"
      ],
      "metadata": {
        "id": "1gcDy97xN4p6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "IcYi1z7uN6HJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None,max_id],dropout=0.2),\n",
        "    keras.layers.GRU(128, return_sequences=True,\n",
        "                     #dropout=0.2, recurrent_dropout=0.2),\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "history=model.fit(dataset, epochs=20)\n",
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSHxXdjHN7Ku",
        "outputId": "0fe164fb-b699-4191-a965-2bf897fed8e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "34822/34822 [==============================] - 576s 16ms/step - loss: 1.7377\n",
            "Epoch 2/20\n",
            "34822/34822 [==============================] - 520s 15ms/step - loss: 1.6520\n",
            "Epoch 3/20\n",
            "34822/34822 [==============================] - 526s 15ms/step - loss: 1.6317\n",
            "Epoch 4/20\n",
            "34822/34822 [==============================] - 515s 15ms/step - loss: 1.6210\n",
            "Epoch 5/20\n",
            "34822/34822 [==============================] - 521s 15ms/step - loss: 1.6141\n",
            "Epoch 6/20\n",
            "34822/34822 [==============================] - 530s 15ms/step - loss: 1.6093\n",
            "Epoch 7/20\n",
            "34822/34822 [==============================] - 511s 15ms/step - loss: 1.6063\n",
            "Epoch 8/20\n",
            "34822/34822 [==============================] - 513s 15ms/step - loss: 1.6037\n",
            "Epoch 9/20\n",
            "34822/34822 [==============================] - 516s 15ms/step - loss: 1.6010\n",
            "Epoch 10/20\n",
            "34822/34822 [==============================] - 516s 15ms/step - loss: 1.5988\n",
            "Epoch 11/20\n",
            "34822/34822 [==============================] - 518s 15ms/step - loss: 1.5974\n",
            "Epoch 12/20\n",
            "34822/34822 [==============================] - 519s 15ms/step - loss: 1.5957\n",
            "Epoch 13/20\n",
            "34822/34822 [==============================] - 523s 15ms/step - loss: 1.5944\n",
            "Epoch 14/20\n",
            "34822/34822 [==============================] - 540s 15ms/step - loss: 1.5932\n",
            "Epoch 15/20\n",
            "34822/34822 [==============================] - 525s 15ms/step - loss: 1.5920\n",
            "Epoch 16/20\n",
            "34822/34822 [==============================] - 522s 15ms/step - loss: 1.5909\n",
            "Epoch 17/20\n",
            "34822/34822 [==============================] - 520s 15ms/step - loss: 1.5899\n",
            "Epoch 18/20\n",
            "34822/34822 [==============================] - 520s 15ms/step - loss: 1.5891\n",
            "Epoch 19/20\n",
            "34822/34822 [==============================] - 522s 15ms/step - loss: 1.5880\n",
            "Epoch 20/20\n",
            "34822/34822 [==============================] - 524s 15ms/step - loss: 1.5875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('my_model.h5')"
      ],
      "metadata": {
        "id": "o2NPZpz0OHJ6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YRRpdQfOLCP",
        "outputId": "d25b8ef8-336c-48d8-f81c-5b9b95c983bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, None, 128)         79488     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, None, 128)         99072     \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, None, 77)          9933      \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 188493 (736.30 KB)\n",
            "Trainable params: 188493 (736.30 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(texts):\n",
        "  X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
        "  return tf.one_hot(X, max_id)"
      ],
      "metadata": {
        "id": "DchsCPe6OL6v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = preprocess([\"How are yo\"])\n",
        "Y_pred_prob = model.predict(X_new)\n",
        "Y_pred_classes = np.argmax(Y_pred_prob, axis=-1)\n",
        "\n",
        "predicted_text = tokenizer.sequences_to_texts(Y_pred_classes +1)[0][-1]\n",
        "print(predicted_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fuSj8P9OOP2",
        "outputId": "de078de7-ef62-4306-a05c-dae039431ed3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 597ms/step\n",
            "u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "  X_new = preprocess([text])\n",
        "  y_proba = model.predict(X_new)[0, -1:, :]\n",
        "  rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "  char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
        "  return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "metadata": {
        "id": "ZXjtC-vUOPi5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\n",
        "  for _ in range(n_chars):\n",
        "    text += next_char(text, temperature)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Z02JrvLDOSaR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(complete_text(\"t\", temperature=0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Sa8QodOUFB",
        "outputId": "cd33b1e5-83ce-41b5-d328-a5c1f1c869e3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "the steel way started to the deck, and the mast-hea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "batch_size = 32\n",
        "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
        "datasets = []\n",
        "for encoded_part in encoded_parts:\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
        "  dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "  datasets.append(dataset)\n",
        "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "dataset = dataset.map(\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch)\n",
        ")\n",
        "dataset = dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "783la20kOVfY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2,batch_input_shape=[batch_size, None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
        "                     dropout=0.2),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "metadata": {
        "id": "Ag9hJVuoOW0h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResetStatesCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self, epoch, logs):\n",
        "    self.model.reset_states()"
      ],
      "metadata": {
        "id": "jiLuf2uVOYLH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "stateful_model.fit(dataset, epochs=50, callbacks=[ResetStatesCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0z7v0QwOZOi",
        "outputId": "109cf384-1495-47f8-9eae-9e10c6c38b25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "348/348 [==============================] - 9s 15ms/step - loss: 2.6847\n",
            "Epoch 2/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 2.2927\n",
            "Epoch 3/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 2.1708\n",
            "Epoch 4/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 2.1025\n",
            "Epoch 5/50\n",
            "348/348 [==============================] - 7s 20ms/step - loss: 2.0564\n",
            "Epoch 6/50\n",
            "348/348 [==============================] - 5s 16ms/step - loss: 2.0235\n",
            "Epoch 7/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.9956\n",
            "Epoch 8/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.9767\n",
            "Epoch 9/50\n",
            "348/348 [==============================] - 7s 19ms/step - loss: 1.9585\n",
            "Epoch 10/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.9428\n",
            "Epoch 11/50\n",
            "348/348 [==============================] - 7s 20ms/step - loss: 1.9304\n",
            "Epoch 12/50\n",
            "348/348 [==============================] - 7s 19ms/step - loss: 1.9212\n",
            "Epoch 13/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.9096\n",
            "Epoch 14/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.9021\n",
            "Epoch 15/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8928\n",
            "Epoch 16/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.8878\n",
            "Epoch 17/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8813\n",
            "Epoch 18/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8732\n",
            "Epoch 19/50\n",
            "348/348 [==============================] - 7s 20ms/step - loss: 1.8666\n",
            "Epoch 20/50\n",
            "348/348 [==============================] - 5s 16ms/step - loss: 1.8604\n",
            "Epoch 21/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.8565\n",
            "Epoch 22/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8515\n",
            "Epoch 23/50\n",
            "348/348 [==============================] - 5s 16ms/step - loss: 1.8464\n",
            "Epoch 24/50\n",
            "348/348 [==============================] - 5s 16ms/step - loss: 1.8418\n",
            "Epoch 25/50\n",
            "348/348 [==============================] - 7s 20ms/step - loss: 1.8402\n",
            "Epoch 26/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8350\n",
            "Epoch 27/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.8328\n",
            "Epoch 28/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8286\n",
            "Epoch 29/50\n",
            "348/348 [==============================] - 7s 20ms/step - loss: 1.8268\n",
            "Epoch 30/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 1.8249\n",
            "Epoch 31/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8217\n",
            "Epoch 32/50\n",
            "348/348 [==============================] - 7s 19ms/step - loss: 1.8179\n",
            "Epoch 33/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.8169\n",
            "Epoch 34/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8125\n",
            "Epoch 35/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8132\n",
            "Epoch 36/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.8092\n",
            "Epoch 37/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 1.8104\n",
            "Epoch 38/50\n",
            "348/348 [==============================] - 6s 16ms/step - loss: 1.8052\n",
            "Epoch 39/50\n",
            "348/348 [==============================] - 6s 16ms/step - loss: 1.8039\n",
            "Epoch 40/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 1.8033\n",
            "Epoch 41/50\n",
            "348/348 [==============================] - 6s 16ms/step - loss: 1.8014\n",
            "Epoch 42/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.7999\n",
            "Epoch 43/50\n",
            "348/348 [==============================] - 5s 15ms/step - loss: 1.8000\n",
            "Epoch 44/50\n",
            "348/348 [==============================] - 7s 21ms/step - loss: 1.7975\n",
            "Epoch 45/50\n",
            "348/348 [==============================] - 6s 16ms/step - loss: 1.7948\n",
            "Epoch 46/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 1.7941\n",
            "Epoch 47/50\n",
            "348/348 [==============================] - 6s 17ms/step - loss: 1.7935\n",
            "Epoch 48/50\n",
            "348/348 [==============================] - 6s 18ms/step - loss: 1.7928\n",
            "Epoch 49/50\n",
            "348/348 [==============================] - 7s 19ms/step - loss: 1.7889\n",
            "Epoch 50/50\n",
            "348/348 [==============================] - 5s 16ms/step - loss: 1.7891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f9a4583f940>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stateful_model.save('my_model_stateful.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q7k3syPOdAo",
        "outputId": "5840c534-237b-4cab-d692-881d1cd38a3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model = keras.models.Sequential([\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
        "                                                    activation=\"softmax\"))\n",
        "])"
      ],
      "metadata": {
        "id": "1YyB0N2tOfYF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stateless_model.build(tf.TensorShape([None, None, max_id]))\n",
        "stateless_model.set_weights(model.get_weights())\n",
        "model = stateless_model\n",
        "tf.random.set_seed(42)\n",
        "print(complete_text(\"t\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLJbxPswOggh",
        "outputId": "b1f84008-8660-4109-ff76-22b1e6d29ec3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 554ms/step\n",
            "1/1 [==============================] - 1s 562ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "t the luster of all this jags in the devel parster \n"
          ]
        }
      ]
    }
  ]
}